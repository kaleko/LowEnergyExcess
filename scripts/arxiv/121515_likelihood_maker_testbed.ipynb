{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from ROOT import TFile, TTree\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "from root_numpy import root2array\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filebase = '/Users/davidkaleko/larlite/UserDev/LowEnergyExcess/output/'\n",
    "#filebase += '70KV/perfect_reco/nopi0alg/'\n",
    "filebase += '70KV/perfect_reco/pi0alg_topoflist/'\n",
    "#filebase += '70KV/perfect_reco/pi0alg_aftercosmics/'\n",
    "\n",
    "\n",
    "filenames = OrderedDict([('nue','singleE_nue_selection_mc.root'),\n",
    "                         ('numu','singleE_numu_selection_mc.root'),\n",
    "                         ('nc','singleE_nc_selection_mc.root'),\n",
    "                         ('cosmic','singleE_cosmic_selection_mc.root') ])#,\n",
    "#                        ('lee','singleE_LEE_selection_mc.root')\n",
    "#                        ])\n",
    "treenames = { 'nue' : 'beamNuE',\n",
    "             'cosmic' : 'cosmicShowers',\n",
    "             'numu' : 'beamNuMu',\n",
    "             'nc' : 'beamNC',\n",
    "            'lee' : 'LEETree'}\n",
    "labels = { 'nue' : 'Beam Intrinsic Nue',\n",
    "         'cosmic' : 'CRY Cosmic, in-time',\n",
    "         'numu' : 'Beam Intrinsic Numu',\n",
    "         'nc' : 'Beam Intrinsic NC', \n",
    "         'lee' : 'Scaled Low Energy Excess'}\n",
    "colors = { 'nue' : '#269729', #kGreen-2\n",
    "         'numu' : '#4B4EAC', #kBlue-5\n",
    "          'nc' : '#6B70F5', #kBlue-9\n",
    "          'cosmic' : '#D12C2C', #kRed-3\n",
    "          'lee' : '#E65C00' #orangish\n",
    "          }\n",
    "#binning = np.linspace(0.1,3,15)\n",
    "binning = np.linspace(0.1,3,39)\n",
    "#binning = np.linspace(0.1,3,15)\n",
    "#binning = np.linspace(-1,1,39)\n",
    "scaling_weights = { 'nue' : 6.6e20/(2.706e15*99600), #should be 99600, used 96000 for collab meeting\n",
    "             'cosmic' : 2.52, #(211,000 ms total exposure)/(6.4ms * 13100 evts generated)\n",
    "             'numu' : 6.6e20/(2.706e15*99600),\n",
    "             'nc' : 6.6e20/(2.706e15*99600),\n",
    "                  'lee' : 1}\n",
    "#10cm from all sides\n",
    "fidvolcut = '_x_vtx > 10 and _x_vtx < 246.35 and _y_vtx > -106.5 and _y_vtx < 106.5 and _z_vtx > 10 and _z_vtx < 1026.8'\n",
    "defaultcut = '_longestTrackLen < 100.'\n",
    "coscut = 'costheta > 0.5'\n",
    "\n",
    "plot_variable = '_e_nuReco'#'ptoverp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfs = OrderedDict()\n",
    "for key, filename in filenames.iteritems():\n",
    "    dfs.update( { key : pd.DataFrame( root2array( filebase + filename, treenames[key] ) ) } )\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in dfs.keys():\n",
    "    #quick add column to df that is cosine of another column\n",
    "    dfs[key]['ecostheta'] = np.cos(dfs[key]['_e_theta'])\n",
    "    dfs[key]['nucostheta'] = np.cos(dfs[key]['_nu_theta'])\n",
    "    dfs[key]['ptoverp'] = dfs[key]['_nu_pt']/dfs[key]['_nu_p']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10,6])\n",
    "for key in dfs.keys():\n",
    "    x = np.array(dfs[key]['ptoverp'])\n",
    "    y = np.array(dfs[key]['_y_vtx'])\n",
    "    plt.plot(x,y,'o',label=key)\n",
    "plt.legend(loc=3)\n",
    "plt.xlabel('Reconstructed Neutrino pt/p')\n",
    "plt.ylabel('Reconstructed neutrino y-vertex')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Let's do a logistic regression to classify if an event is nue or cosmic\n",
    "#(todo: how is this different than a log likelihood?)\n",
    "# y = 0 means cosmic, y = 1 means nue\n",
    "\n",
    "#Build the feature matrix, X, from cosmic samples (with y = 0) and nue samples (with y = 1)\n",
    "cosX = dfs['cosmic'][['ptoverp', '_y_vtx']].as_matrix()\n",
    "cosX = np.insert(cosX,0,1,axis=1)\n",
    "cosy = np.zeros((cosX.shape[0],1))\n",
    "nueX = dfs['nue'][['ptoverp', '_y_vtx']].as_matrix()\n",
    "nueX = np.insert(nueX,0,1,axis=1)\n",
    "nuey = np.ones((nueX.shape[0],1))\n",
    "X = np.vstack((cosX,nueX))\n",
    "y = np.vstack((cosy,nuey))\n",
    "m = y.size # number of training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plot the data to make sure it looks good\n",
    "def plotData():\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(cosX[:,1],cosX[:,2],'co',label='Cosmics')\n",
    "    plt.plot(nueX[:,1],nueX[:,2],'ro',label='Nues')\n",
    "    plt.xlabel('Reconstructed Neutrino pt/p')\n",
    "    plt.ylabel('Reconstructed Neutrino y-vertex')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "plotData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Feature normalizing the columns (subtract mean, divide by standard deviation)\n",
    "#Store the mean and std for later use\n",
    "#Note don't modify the original X matrix, use a copy\n",
    "stored_feature_means, stored_feature_stds = [], []\n",
    "Xnorm = X.copy()\n",
    "for icol in xrange(Xnorm.shape[1]):\n",
    "    stored_feature_means.append(np.mean(Xnorm[:,icol]))\n",
    "    stored_feature_stds.append(np.std(Xnorm[:,icol]))\n",
    "    #Skip the first column\n",
    "    if not icol: continue\n",
    "    #Faster to not recompute the mean and std again, just used stored values\n",
    "    Xnorm[:,icol] = (Xnorm[:,icol] - stored_feature_means[-1])/stored_feature_stds[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Build the logistic regression:\n",
    "from scipy.special import expit #Vectorized sigmoid function\n",
    "\n",
    "#Hypothesis function and cost function for logistic regression\n",
    "def h(mytheta,myX): #Logistic hypothesis function\n",
    "    return expit(np.dot(myX,mytheta))\n",
    "\n",
    "#Cost function, default lambda (regularization) 0\n",
    "def computeCost(mytheta,myX,myy,mylambda = 0.): \n",
    "    \"\"\"\n",
    "    theta_start is an n- dimensional vector of initial theta guess\n",
    "    X is matrix with n- columns and m- rows\n",
    "    y is a matrix with m- rows and 1 column\n",
    "    Note this includes regularization, if you set mylambda to nonzero\n",
    "    For the first part of the homework, the default 0. is used for mylambda\n",
    "    \"\"\"\n",
    "    #note to self: *.shape is (rows, columns)\n",
    "    term1 = np.dot(-np.array(myy).T,np.log(h(mytheta,myX)))\n",
    "    term2 = np.dot((1-np.array(y)).T,np.log(1-h(mytheta,myX)))\n",
    "    regterm = (mylambda/2) * np.sum(np.dot(mytheta[1:].T,mytheta[1:])) #Skip theta0\n",
    "    return float( (1./m) * ( np.sum(term1 - term2) + regterm ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Optimization functions:\n",
    "#An alternative to OCTAVE's 'fminunc' we'll use some scipy.optimize function, \"fmin\"\n",
    "#Note \"fmin\" does not need to be told explicitly the derivative terms\n",
    "#It only needs the cost function, and it minimizes with the \"downhill simplex algorithm.\"\n",
    "#http://docs.scipy.org/doc/scipy-0.16.0/reference/generated/scipy.optimize.fmin.html\n",
    "from scipy import optimize\n",
    "\n",
    "def optimizeTheta(mytheta,myX,myy,mylambda=0.):\n",
    "    result = optimize.fmin(computeCost, x0=mytheta, args=(myX, myy, mylambda), maxiter=400, full_output=True)\n",
    "    return result[0], result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plug in a random initial theta and solve for the coefficients:\n",
    "initial_theta = np.zeros((Xnorm.shape[1],1))\n",
    "theta, mincost = optimizeTheta(initial_theta,Xnorm,y)\n",
    "print theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print h(np.array(theta),np.array([[1,0,-100]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import necessary matplotlib tools for 3d plots\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D\n",
    "from matplotlib import cm\n",
    "import itertools\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "xvals = np.arange(-1,1,.05)\n",
    "yvals = np.arange(-125,125,5)\n",
    "myxs, myys, myzs = [], [], []\n",
    "for david in xvals:\n",
    "    for kaleko in yvals:\n",
    "        myxs.append(david)\n",
    "        myys.append(kaleko)\n",
    "        testpoint = np.array([david,kaleko])\n",
    "        #To \"undo\" feature normalization, we \"undo\" 1650 and 3, then plug it into our hypothesis\n",
    "        testpointscaled = [(testpoint[x]-stored_feature_means[x+1])/stored_feature_stds[x+1] for x in xrange(len(testpoint))]\n",
    "        testpointscaled.insert(0,1)\n",
    "        myzs.append(h(np.array(theta),np.array([testpointscaled])))\n",
    "\n",
    "scat = ax.scatter(myxs,myys,myzs,c=np.abs(myzs),cmap=plt.get_cmap('YlOrRd'))\n",
    "\n",
    "plt.xlabel('Neutrino pt/p',fontsize=30)\n",
    "plt.ylabel('Neutrino y-vertex',fontsize=30)\n",
    "plt.title('Hypothesis (1 = nue, 0 = cosmic)',fontsize=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Hacky insert 0 in stored feature mean and 1 in stored feature stds\n",
    "stored_feature_means[0]=0\n",
    "stored_feature_stds[0]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now that we have an optimized theta fit parameter vector, add hypothesis as a column to each df\n",
    "for key in dfs.keys():\n",
    "    testpoints = np.array([dfs[key]['ptoverp'],dfs[key]['_y_vtx']]).T\n",
    "    testpoints = np.insert(testpoints,0,1,axis=1)\n",
    "    testpointsscaled = (testpoints-stored_feature_means)/stored_feature_stds\n",
    "    dfs[key]['hypothesis'] = h(np.array(theta),np.array([testpointsscaled])).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mybins = np.linspace(0,1,50)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(dfs['cosmic']['hypothesis'],label='Cosmics',alpha=0.5,bins=mybins)\n",
    "plt.hist(dfs['nue']['hypothesis'],label='Nue',alpha=0.5,bins=mybins)\n",
    "plt.legend(loc=2)\n",
    "plt.xlabel(\"Hypothesis Value (1 = Nue, 0 = Cosmic)\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gen_histos(myquery=''):\n",
    "    nphistos = OrderedDict()\n",
    "\n",
    "    for key, df in dfs.iteritems():\n",
    "        if key == 'lee': continue\n",
    "        mydf = df.query(myquery) if myquery else df\n",
    "        if key == 'cosmic':\n",
    "            myweights = np.ones(mydf[plot_variable].shape[0])\n",
    "        else:\n",
    "            #NOTE: using ravel() seems to actually modify the dataframe itself\n",
    "            #which causes weird behavior when this function is called repeatedly\n",
    "            #so just cast the series as an array (as done below) instead.\n",
    "            #I don't understand why ravel() modifies the DF.\n",
    "            myweights = np.array(mydf['_weight'])#.ravel()\n",
    "        myweights *= scaling_weights[key]\n",
    "        nphistos.update( {key : np.histogram(mydf[plot_variable]/1000.,\n",
    "                                     bins=binning,\n",
    "                                     weights=myweights)} )\n",
    "    return nphistos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_fullstack(myhistos):\n",
    "    fig = plt.figure(figsize=(10,6))\n",
    "    plt.grid(True)\n",
    "    lasthist = 0\n",
    "    for key, (hist, bins) in myhistos.iteritems():\n",
    "        if key == 'lee': continue\n",
    "        plt.bar(bins[:-1],hist,\n",
    "                width=bins[1]-bins[0],\n",
    "                color=colors[key],\n",
    "                bottom = lasthist,\n",
    "                edgecolor = 'k',\n",
    "                label='%s: %d Events'%(labels[key],sum(hist)))\n",
    "        lasthist += hist\n",
    "    \n",
    "    plt.xlim([binning[0],binning[-1]])\n",
    "    #plt.ylim([0,400])\n",
    "    plt.title('CCSingleE Stacked Backgrounds',fontsize=25)\n",
    "    plt.ylabel('Events',fontsize=20)\n",
    "    if plot_variable == '_e_nuReco':\n",
    "        xstring = 'Reconstructed Neutrino Energy [GeV]' \n",
    "    else:\n",
    "        xstring = 'pT/p Reconstructed Neutrino'\n",
    "    plt.xlabel(xstring,fontsize=20)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#nphistos = gen_histos('_is_fiducial==True and _longestTrackLen < 1')\n",
    "plot_fullstack(gen_histos())\n",
    "plot_fullstack(gen_histos('hypothesis > 0.5'))\n",
    "#plot_fullstack(gen_histos(defaultcut))\n",
    "#plot_fullstack(gen_histos(defaultcut + ' and ' + fidvolcut))\n",
    "plot_fullstack(gen_histos(defaultcut + ' and ' + fidvolcut + ' and ' + 'hypothesis > 0.5'))\n",
    "#plot_fullstack(gen_histos())\n",
    "#plot_fullstack(gen_histos(fidvolcut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numu_MIDs = dfs['numu'].query(defaultcut + ' and ' + fidvolcut + ' and ' + 'hypothesis > 0.5')\n",
    "\n",
    "numu_MIDs.hist('_parentPDG',bins=np.linspace(-100,200,300))\n",
    "numu_MIDs['_is_fiducial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numu_MIDs.query('_parentPDG == 13 or _parentPDG == -13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\\]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
